{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7063de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9ae8274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25d376",
   "metadata": {},
   "source": [
    "### Inizialize parameters, tokenizer, and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61803c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "MAX_GRAD_NORM = 10\n",
    "\n",
    "# temp_labels = ['M', 'F', 'O']\n",
    "# label2id = {k: v for v, k in enumerate(temp_labels)}\n",
    "# id2label = {v: k for v, k in enumerate(temp_labels)}\n",
    "temp_labels = ['O', 'Generic she', 'Generic he',\n",
    "               'Behavioural Stereotypes', 'i-Behavioural Stereotypes',\n",
    "               'Societal Stereotypes', 'i-Societal Stereotypes',\n",
    "               'Explicit Marking of Sex', 'i-Explicit Marking of Sex']\n",
    "\n",
    "label2id = {k: v for v, k in enumerate(temp_labels)}\n",
    "id2label = {v: k for v, k in enumerate(temp_labels)}\n",
    "label2id\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForTokenClassification.from_pretrained(\"Models/model_annotated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadfc501",
   "metadata": {},
   "source": [
    "### Load test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4575d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_custom_labeled = pd.read_csv('Data/test_custom_labeled.csv')\n",
    "# test_hugging_face = pd.read_csv('Data/test_hugging_face.csv')\n",
    "test_annotated = pd.read_csv('Data/test_data_annotated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5679be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O,O,O,O,Societal Stereotypes,O,O,O,Behavioural Stereotypes,O,O,O,O,O,O,O',\n",
       "       'The post involves supporting individuals to live as independently as possible in their own homes.'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_annotated.values[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122c5c37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9344b2",
   "metadata": {},
   "source": [
    "### Predict single sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adccdca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "are you the master of technology and passionate person we are looking for ?\n",
      "\n",
      "PRED:['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'Behavioural Stereotypes', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "sentence = test_annotated.sentence[13]\n",
    "sentence = \"We are committed to building better neighborhoods wherever we are, not only for our residents, but for the greater community\"\n",
    "sentence = \"Ideal candidates will be caring, compassionate, adaptable, flexible, committed to high standards of care and possess excellent communication skills both verbal and written.\"\n",
    "#sentence = \"the post involves supporting people to live as independently as possible in their own homes .\"\n",
    "#sentence = \"A programmer must carry his laptop with him to work.\" \n",
    "#sentence = \"A nurse should ensure that she  gets adequate rest\"\n",
    "#sentence = \"He / She is suitable for this position.\"\n",
    "sentence = \"Must be an extrovert who has innate quality of easily connecting with people!\"\n",
    "sentence = \"Are you the master of technology and passionate person we are looking for?\"\n",
    "inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors=\"pt\")\n",
    "\n",
    "ids = inputs[\"input_ids\"].to(device)\n",
    "mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "outputs = model(ids, mask)\n",
    "logits = outputs[0]\n",
    "\n",
    "active_logits = logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n",
    "\n",
    "m = torch.nn.Softmax(dim=1)\n",
    "probabilities = m(logits[0])\n",
    "prediction_probability = torch.max(probabilities, axis=1)[0].tolist()\n",
    "prediction_probability = [ '%.3f' % elem for elem in prediction_probability ]\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "token_predictions = [id2label[i] for i in flattened_predictions.cpu().numpy()]\n",
    "wp_preds = list(zip(tokens, token_predictions, prediction_probability)) # list of tuples. Each tuple = (wordpiece, prediction)\n",
    "\n",
    "\n",
    "word_level_predictions = []\n",
    "word_level_probabilities = []\n",
    "for pair in wp_preds:\n",
    "    if (pair[0].startswith(\" ##\")) or (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n",
    "    # skip prediction\n",
    "        continue\n",
    "    else:\n",
    "        word_level_predictions.append(pair[1])\n",
    "        word_level_probabilities.append(pair[2])\n",
    "\n",
    "# we join tokens, if they are not special ones\n",
    "str_rep = \" \".join([t[0] for t in wp_preds if t[0] not in ['[CLS]', '[SEP]', '[PAD]']]).replace(\" ##\", \"\")\n",
    "print(str_rep)\n",
    "print()\n",
    "print('PRED:' + str(word_level_predictions))\n",
    "#print(word_level_probabilities)\n",
    "#print('TRUE:' + str(test_annotated.word_labels[13].split(',')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c45e2e",
   "metadata": {},
   "source": [
    "### Use softmax for probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f50b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.nn.Softmax(dim=1)\n",
    "probabilities = m(logits[0])\n",
    "max_probability = torch.max(probabilities, axis=1)\n",
    "boolean_mask = torch.as_tensor(list(map(bool,mask[0])))\n",
    "filtered_probabilities = torch.masked_select(max_probability[0], boolean_mask).tolist()\n",
    "filtered_probabilities = [ '%.2f' % elem for elem in filtered_probabilities ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c377c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.00', '1.00', '1.00', '1.00', '1.00', '0.50', '1.00', '1.00', '1.00', '0.92', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '1.00', '0.98']\n"
     ]
    }
   ],
   "source": [
    "print(filtered_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9624e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_labels</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>O,O,O,O,O,Behavioural Stereotypes,O,O,O,O,O,O,...</td>\n",
       "      <td>Athletes receive their training plans, connect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O,O,O,O,O,Behavioural Stereotypes,O,O,O,O,O,O,...</td>\n",
       "      <td>Athletes receive their training plans, connect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "      <td>Analyze Telecom (wireless and wireline) and Ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "      <td>In return, you can expect an attractive salary...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,Behavioural Stereotypes,O,...</td>\n",
       "      <td>Probing as to what they want and present what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "      <td>The department is very people-oriented both in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "      <td>More than 4,000 of the world’s most demanding ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "      <td>Our drivers average 10+ years on the job and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "      <td>We offer you a chance to join an agile team of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "      <td>We pride ourselves on our flat hierarchy as th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           word_labels  \\\n",
       "0    O,O,O,O,O,Behavioural Stereotypes,O,O,O,O,O,O,...   \n",
       "1    O,O,O,O,O,Behavioural Stereotypes,O,O,O,O,O,O,...   \n",
       "2        O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O   \n",
       "3      O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O   \n",
       "4    O,O,O,O,O,O,O,O,O,O,Behavioural Stereotypes,O,...   \n",
       "..                                                 ...   \n",
       "156  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...   \n",
       "157  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...   \n",
       "158              O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O   \n",
       "159  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...   \n",
       "160  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...   \n",
       "\n",
       "                                              sentence  \n",
       "0    Athletes receive their training plans, connect...  \n",
       "1    Athletes receive their training plans, connect...  \n",
       "2    Analyze Telecom (wireless and wireline) and Ne...  \n",
       "3    In return, you can expect an attractive salary...  \n",
       "4    Probing as to what they want and present what ...  \n",
       "..                                                 ...  \n",
       "156  The department is very people-oriented both in...  \n",
       "157  More than 4,000 of the world’s most demanding ...  \n",
       "158  Our drivers average 10+ years on the job and a...  \n",
       "159  We offer you a chance to join an agile team of...  \n",
       "160  We pride ourselves on our flat hierarchy as th...  \n",
       "\n",
       "[161 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_annotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
