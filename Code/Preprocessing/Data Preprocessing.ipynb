{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "#from pattern.text.en import singularize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\veselin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    #text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.replace(':', ' ')\n",
    "    text = text.replace('\\'', ' ')\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    # Remove whitespace from text\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    # Remove stopwords function\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    text = [word for word in word_tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatize words\n",
    "    #text = [lemmatizer.lemmatize(word, pos ='v') for word in text]\n",
    "    \n",
    "    # Stem words \n",
    "    #text = [stemmer.stem(word) for word in text]\n",
    "    \n",
    "    return text\n",
    "\n",
    "\n",
    "def simple_clean(text):\n",
    "    # Lowercase text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove numbers\n",
    "    #text = re.sub(r'\\d+', '', text)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences = pd.read_csv('sentences.csv')\n",
    "df_biased_words = pd.read_excel(\"bias_words.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_exclude = ['she', 'her', 'hers', 'herself', 'he', 'himself', 'him', 'his']\n",
    "df_biased_words = df_biased_words[~df_biased_words['Biased Words or Phrases'].isin(to_exclude)]\n",
    "df_biased_words = df_biased_words.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_words = (df_biased_words.loc[df_biased_words['Masculine/Feminine Bias'] == 'Masculine Bias'])['Biased Words or Phrases'].values\n",
    "female_words = (df_biased_words.loc[df_biased_words['Masculine/Feminine Bias'] == 'Feminine Bias'])['Biased Words or Phrases'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# male_words = df_biased_words['male']\n",
    "# male_words = male_words.dropna()\n",
    "# male_words = [stemmer.stem(word) for word in male_words]\n",
    "# female_words = df_biased_words['female']\n",
    "# female_words = female_words.dropna()\n",
    "# female_words = [stemmer.stem(word) for word in female_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activ',\n",
       " 'adventur',\n",
       " 'aggress',\n",
       " 'ambitio',\n",
       " 'anali',\n",
       " 'assert',\n",
       " 'athlet',\n",
       " 'autonom',\n",
       " 'boast',\n",
       " 'challeng',\n",
       " 'compet',\n",
       " 'confid',\n",
       " 'courag',\n",
       " 'decid',\n",
       " 'decis',\n",
       " 'decis',\n",
       " 'determin',\n",
       " 'domin',\n",
       " 'domina',\n",
       " 'forc',\n",
       " 'greedi',\n",
       " 'headstrong',\n",
       " 'hierarch',\n",
       " 'hostil',\n",
       " 'implus',\n",
       " 'independen',\n",
       " 'individu',\n",
       " 'intellect',\n",
       " 'lead',\n",
       " 'logic',\n",
       " 'masculin',\n",
       " 'object',\n",
       " 'opinion',\n",
       " 'outspoken',\n",
       " 'persist',\n",
       " 'principl',\n",
       " 'reckless',\n",
       " 'stubborn',\n",
       " 'superior',\n",
       " 'self-confiden',\n",
       " 'self-sufficien',\n",
       " 'self-relian',\n",
       " 'manmad',\n",
       " 'chairman',\n",
       " 'son',\n",
       " 'fireman',\n",
       " 'freshman',\n",
       " 'man',\n",
       " 'mankind',\n",
       " 'manpow',\n",
       " 'boyfriend',\n",
       " 'husband',\n",
       " 'policeman',\n",
       " 'walter',\n",
       " 'brother',\n",
       " 'spokesman',\n",
       " 'upperclassman',\n",
       " 'he',\n",
       " 'him',\n",
       " 'hi',\n",
       " 'himself',\n",
       " 'gentleman',\n",
       " 'alumnu',\n",
       " 'alumni',\n",
       " 'man up',\n",
       " 'mr.',\n",
       " 'man-mad',\n",
       " 'the common man',\n",
       " 'mailman',\n",
       " 'steward',\n",
       " 'actor',\n",
       " 'congressman']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['she',\n",
       " 'affection',\n",
       " 'child',\n",
       " 'cheer',\n",
       " 'commit',\n",
       " 'commun',\n",
       " 'compass',\n",
       " 'connect',\n",
       " 'consider',\n",
       " 'cooperat',\n",
       " 'depend',\n",
       " 'emotiona',\n",
       " 'empath',\n",
       " 'feminin',\n",
       " 'flatter',\n",
       " 'gentl',\n",
       " 'honest',\n",
       " 'interperson',\n",
       " 'interdependen',\n",
       " 'interpersona',\n",
       " 'kind',\n",
       " 'kinship',\n",
       " 'loyal',\n",
       " 'modesti',\n",
       " 'nag',\n",
       " 'nurtur',\n",
       " 'pleasant',\n",
       " 'polit',\n",
       " 'quiet',\n",
       " 'respon',\n",
       " 'sensitiv',\n",
       " 'submiss',\n",
       " 'support',\n",
       " 'sympath',\n",
       " 'tender',\n",
       " 'togeth',\n",
       " 'trust',\n",
       " 'understand',\n",
       " 'warm',\n",
       " 'whin',\n",
       " 'yield',\n",
       " 'daughter',\n",
       " 'wife',\n",
       " 'girlfriend',\n",
       " 'waitress',\n",
       " 'sister',\n",
       " 'her',\n",
       " 'her',\n",
       " 'herself',\n",
       " 'ladi',\n",
       " 'alumna',\n",
       " 'alumna',\n",
       " 'hyster',\n",
       " 'shrill',\n",
       " 'nag',\n",
       " 'mrs.',\n",
       " 'miss.',\n",
       " 'ms.',\n",
       " 'stewardess',\n",
       " 'actress',\n",
       " 'wife',\n",
       " 'sister',\n",
       " 'she',\n",
       " 'her']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame()\n",
    "\n",
    "for index, sentence in df_sentences.iterrows():\n",
    "    temp_sentence = sentence['sentences']\n",
    "    tokenized_sentence = clean(temp_sentence)\n",
    "    category = 'neutral'\n",
    "    word_in_sentence = 'None'\n",
    "    word = 'None'\n",
    "    \n",
    "    # check for male words\n",
    "    for male_word in male_words:\n",
    "        if re.search(r\"\\b{}\\b\".format(male_word), temp_sentence.lower().strip()):\n",
    "            category = 'masculine'\n",
    "            word_in_sentence = male_word\n",
    "            word = male_word\n",
    "        else:\n",
    "            for token in tokenized_sentence:\n",
    "                if len(male_word) > 3:\n",
    "\n",
    "                    if simple_clean(male_word) == token[:len(male_word)]:\n",
    "                        category = 'masculine'\n",
    "                        word_in_sentence = token\n",
    "                        word = male_word\n",
    "                    elif simple_clean(male_word) == token[-len(male_word):]:\n",
    "                        category = 'masculine'\n",
    "                        word_in_sentence = token\n",
    "                        word = male_word\n",
    "            \n",
    "    if category == 'masculine':\n",
    "        dict = {'sentence': temp_sentence,\n",
    "                'word_in_Sentence': word_in_sentence,\n",
    "                'biased_term': word,\n",
    "                'category': category\n",
    "               }\n",
    "        df_new = df_new.append(dict, ignore_index = True)\n",
    "        \n",
    "    # check for female words\n",
    "    for female_word in female_words:\n",
    "        if re.search(r\"\\b{}\\b\".format(female_word), temp_sentence.lower().strip()):\n",
    "            category = 'feminine'\n",
    "            word_in_sentence = female_word\n",
    "            word = female_word\n",
    "        else:\n",
    "            for token in tokenized_sentence:\n",
    "                if len(female_word) > 3:\n",
    "                    if simple_clean(female_word) == token[:len(female_word)]:\n",
    "                        category = 'feminine'\n",
    "                        word_in_sentence = token\n",
    "                        word = female_word\n",
    "                    elif simple_clean(female_word) == token[-len(female_word):]:\n",
    "                        category = 'feminine'\n",
    "                        word_in_sentence = token\n",
    "                        word = female_word\n",
    "                    \n",
    "    if category == 'feminine':\n",
    "        dict = {'sentence': temp_sentence,\n",
    "                'word_in_Sentence': word_in_sentence,\n",
    "                'biased_term': word,\n",
    "                'category': category\n",
    "               }\n",
    "        df_new = df_new.append(dict, ignore_index = True)\n",
    "    \n",
    "    if index%10000 == 0:\n",
    "        print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "30000\n",
      "40000\n",
      "60000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "120000\n",
      "130000\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame()\n",
    "\n",
    "for index, sentence in df_sentences.iterrows():\n",
    "    temp_sentence = sentence['sentences']\n",
    "    tokenized_sentence = clean(temp_sentence)\n",
    "    words_in_sentence = []\n",
    "    words = []\n",
    "    \n",
    "    if len(temp_sentence) < 180 and temp_sentence[0].isupper():\n",
    "        # check for male words\n",
    "        for male_word in male_words:\n",
    "            if re.search(r\"\\b{}\\b\".format(male_word), temp_sentence.lower().strip()):\n",
    "                words_in_sentence.append([male_word, 'M'])\n",
    "                words.append([male_word, 'M'])\n",
    "            else:\n",
    "                for token in tokenized_sentence:\n",
    "                    if len(male_word) > 3:\n",
    "                        if simple_clean(male_word) == token[:len(male_word)]:\n",
    "                            words_in_sentence.append([token, 'M'])\n",
    "                            words.append([male_word, 'M'])\n",
    "                        elif simple_clean(male_word) == token[-len(male_word):]:\n",
    "                            if token[:len(male_word)] != token[-len(male_word):]:\n",
    "                                words_in_sentence.append([token, 'M'])\n",
    "                                words.append([male_word, 'M'])\n",
    "\n",
    "        # check for female words\n",
    "        for female_word in female_words:\n",
    "            if re.search(r\"\\b{}\\b\".format(female_word), temp_sentence.lower().strip()):\n",
    "                words_in_sentence.append([female_word, 'F'])\n",
    "                words.append([male_word, 'F'])\n",
    "            else:\n",
    "                for token in tokenized_sentence:\n",
    "                    if len(female_word) > 3:\n",
    "                        if simple_clean(female_word) == token[:len(female_word)]:\n",
    "                            words_in_sentence.append([token, 'F'])\n",
    "                            words.append([female_word, 'F'])\n",
    "                        elif simple_clean(female_word) == token[-len(female_word):]:\n",
    "                            if token[:len(female_word)] != token[-len(female_word):]:\n",
    "                                words_in_sentence.append([token, 'F'])\n",
    "                                words.append([female_word, 'F'])\n",
    "\n",
    "        if len(words) > 0:\n",
    "            dict = {'sentence': temp_sentence,\n",
    "                    'word_in_Sentence': words_in_sentence,\n",
    "                    'biased_term': words}\n",
    "            df_new = df_new.append(dict, ignore_index = True)\n",
    "\n",
    "        if index%10000 == 0:\n",
    "            print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('male_female_last_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biased_term</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[['active', 'M']]</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>[['actively', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[['compet', 'M'], ['competitive', 'M']]</td>\n",
       "      <td>Privately held, we offer exceptional benefits,...</td>\n",
       "      <td>[['competitive', 'M'], ['competitive', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[['respon', 'F']]</td>\n",
       "      <td>As part of an account team, you will be respon...</td>\n",
       "      <td>[['responsible', 'F']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[['lead', 'M']]</td>\n",
       "      <td>Job Overview  Apex is an environmental consult...</td>\n",
       "      <td>[['leadership', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[['respon', 'F']]</td>\n",
       "      <td>Driven by an entrepreneurial spirit and a dedi...</td>\n",
       "      <td>[['responsive', 'F']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26107</th>\n",
       "      <td>[['challeng', 'M']]</td>\n",
       "      <td>Ideally, you love the challenges of being a pr...</td>\n",
       "      <td>[['challenges', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26108</th>\n",
       "      <td>[['individual', 'M']]</td>\n",
       "      <td>In addition, this individual will assist with ...</td>\n",
       "      <td>[['individual', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26109</th>\n",
       "      <td>[['principle', 'M'], ['makes decisions easily'...</td>\n",
       "      <td>Candidate must also possess expertise in appli...</td>\n",
       "      <td>[['principles', 'M'], ['support', 'F']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26110</th>\n",
       "      <td>[['analy', 'M'], ['analytical', 'M']]</td>\n",
       "      <td>Strong analytical skills that will allow prope...</td>\n",
       "      <td>[['analytical', 'M'], ['analytical', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26111</th>\n",
       "      <td>[['makes decisions easily', 'F']]</td>\n",
       "      <td>Able support development and recommend solutio...</td>\n",
       "      <td>[['support', 'F']]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26112 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             biased_term  \\\n",
       "0                                      [['active', 'M']]   \n",
       "1                [['compet', 'M'], ['competitive', 'M']]   \n",
       "2                                      [['respon', 'F']]   \n",
       "3                                        [['lead', 'M']]   \n",
       "4                                      [['respon', 'F']]   \n",
       "...                                                  ...   \n",
       "26107                                [['challeng', 'M']]   \n",
       "26108                              [['individual', 'M']]   \n",
       "26109  [['principle', 'M'], ['makes decisions easily'...   \n",
       "26110              [['analy', 'M'], ['analytical', 'M']]   \n",
       "26111                  [['makes decisions easily', 'F']]   \n",
       "\n",
       "                                                sentence  \\\n",
       "0      Our client, located in Houston, is actively se...   \n",
       "1      Privately held, we offer exceptional benefits,...   \n",
       "2      As part of an account team, you will be respon...   \n",
       "3      Job Overview  Apex is an environmental consult...   \n",
       "4      Driven by an entrepreneurial spirit and a dedi...   \n",
       "...                                                  ...   \n",
       "26107  Ideally, you love the challenges of being a pr...   \n",
       "26108  In addition, this individual will assist with ...   \n",
       "26109  Candidate must also possess expertise in appli...   \n",
       "26110  Strong analytical skills that will allow prope...   \n",
       "26111  Able support development and recommend solutio...   \n",
       "\n",
       "                                   word_in_Sentence  \n",
       "0                               [['actively', 'M']]  \n",
       "1      [['competitive', 'M'], ['competitive', 'M']]  \n",
       "2                            [['responsible', 'F']]  \n",
       "3                             [['leadership', 'M']]  \n",
       "4                             [['responsive', 'F']]  \n",
       "...                                             ...  \n",
       "26107                         [['challenges', 'M']]  \n",
       "26108                         [['individual', 'M']]  \n",
       "26109       [['principles', 'M'], ['support', 'F']]  \n",
       "26110    [['analytical', 'M'], ['analytical', 'M']]  \n",
       "26111                            [['support', 'F']]  \n",
       "\n",
       "[26112 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('male_female_last.csv')\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(sentence):\n",
    "    temp = \" \".join(sentence.split())\n",
    "    temp = temp.strip()\n",
    "\n",
    "    char_to_remove = 0\n",
    "    for x in temp.split()[0]:\n",
    "        if not x.isalpha():\n",
    "            char_to_remove += 1\n",
    "    temp = temp[char_to_remove: len(temp) - char_to_remove]\n",
    "    return sentence\n",
    "\n",
    "df_new['sentence'] = df_new.sentence.map(lambda x:clean_sentence(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore filtered sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masculine    23828\n",
       "feminine     23106\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8332, 7085, 6953, 3067, 2627, 2355, 1402, 1214, 1069, 1022,  965,\n",
       "        859,  809,  712,  681,  536,  519,  487,  460,  430,  407,  379,\n",
       "        331,  326,  308,  286,  266,  250,  203,  195,  186,  167,  163,\n",
       "        143,  109,  102,  101,   99,   98,   94,   90,   75,   75,   66,\n",
       "         64,   58,   53,   51,   49,   44,   41,   37,   35,   33,   32,\n",
       "         30,   30,   27,   25,   24,   23,   22,   22,   20,   19,   18,\n",
       "          7,    7,    6,    6,    5,    5,    5,    5,    3,    3,    3,\n",
       "          3,    3,    2,    2,    1,    1,    1,    1,    1,    1,    1,\n",
       "          1,    1], dtype=int64)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.biased_term.value_counts().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found_words = []\n",
    "found_words = df_new.biased_term.value_counts().keys()\n",
    "for word in list(male_words) + list(female_words):\n",
    "    if word not in found_words:\n",
    "        not_found_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(found_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_found_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aggress',\n",
       " 'headstrong',\n",
       " 'implusive',\n",
       " 'masculine',\n",
       " 'stubborn',\n",
       " 'self-confiden',\n",
       " 'self-sufficien',\n",
       " 'self-relian',\n",
       " 'manmade',\n",
       " 'freshman',\n",
       " 'mankind',\n",
       " 'boyfriend',\n",
       " 'policeman',\n",
       " 'spokesman',\n",
       " 'upperclassman',\n",
       " 'alumnus',\n",
       " 'man up',\n",
       " 'Mr.',\n",
       " 'mankind',\n",
       " 'freshman',\n",
       " 'man-made',\n",
       " 'the common man',\n",
       " 'mailman',\n",
       " 'policeman',\n",
       " 'congressman',\n",
       " 'acts as a leader',\n",
       " 'defends own beliefs',\n",
       " 'forceful',\n",
       " 'has leadership abilities',\n",
       " 'individualistic',\n",
       " 'makes decisions easily',\n",
       " 'affectionate',\n",
       " 'feminine',\n",
       " 'flatterable',\n",
       " 'interpersonal',\n",
       " 'kinship',\n",
       " 'modesty',\n",
       " 'nag',\n",
       " 'submissive',\n",
       " 'whin',\n",
       " 'girlfriend',\n",
       " 'alumna',\n",
       " 'alumnae',\n",
       " 'hysterical',\n",
       " 'shrill',\n",
       " 'nagging',\n",
       " 'Mrs.',\n",
       " 'Ms.',\n",
       " 'stewardess',\n",
       " 'actress']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = pd.DataFrame(columns=df_new.columns)\n",
    "for word in found_words:\n",
    "    temp = df_new.loc[df_new.biased_term == word]\n",
    "    temp = temp.head(6)\n",
    "    frames = [to_save, temp]\n",
    "    to_save = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = to_save.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = to_save.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2, df3, df4 = np.array_split(to_save, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>biased_term</th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "      <th>sort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7574</th>\n",
       "      <td>[['confident', 'M']]</td>\n",
       "      <td>Maintain strict consumer confidentiality.</td>\n",
       "      <td>[['confidentiality', 'M']]</td>\n",
       "      <td>confidentiality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21408</th>\n",
       "      <td>[['confident', 'M']]</td>\n",
       "      <td>You will have your own list of clients to look...</td>\n",
       "      <td>[['confident', 'M']]</td>\n",
       "      <td>confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8928</th>\n",
       "      <td>[['confident', 'M']]</td>\n",
       "      <td>You will be the first person new customers spe...</td>\n",
       "      <td>[['confident', 'M']]</td>\n",
       "      <td>confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8820</th>\n",
       "      <td>[['confident', 'M'], ['lead', 'M']]</td>\n",
       "      <td>They will be confident at leading groups of de...</td>\n",
       "      <td>[['confident', 'M'], ['leading', 'M']]</td>\n",
       "      <td>confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>[['confident', 'M']]</td>\n",
       "      <td>Consultative and confident approach to calls.</td>\n",
       "      <td>[['confident', 'M']]</td>\n",
       "      <td>confident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20279</th>\n",
       "      <td>[['challeng', 'M']]</td>\n",
       "      <td>To be successful in this role you will need to...</td>\n",
       "      <td>[['challenging', 'M']]</td>\n",
       "      <td>challenging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17756</th>\n",
       "      <td>[['challeng', 'M']]</td>\n",
       "      <td>But if you want a role that is fascinating and...</td>\n",
       "      <td>[['challenging', 'M']]</td>\n",
       "      <td>challenging</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24269</th>\n",
       "      <td>[['makes decisions easily', 'F']]</td>\n",
       "      <td>She is looking forward to hiring someone who i...</td>\n",
       "      <td>[['quiet', 'F']]</td>\n",
       "      <td>quiet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11648</th>\n",
       "      <td>[['makes decisions easily', 'F']]</td>\n",
       "      <td>She is looking forward to hiring someone who i...</td>\n",
       "      <td>[['quiet', 'F']]</td>\n",
       "      <td>quiet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12369</th>\n",
       "      <td>[['makes decisions easily', 'F']]</td>\n",
       "      <td>With a history of ‘firsts’, there has been a q...</td>\n",
       "      <td>[['quiet', 'F']]</td>\n",
       "      <td>quiet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               biased_term  \\\n",
       "7574                  [['confident', 'M']]   \n",
       "21408                 [['confident', 'M']]   \n",
       "8928                  [['confident', 'M']]   \n",
       "8820   [['confident', 'M'], ['lead', 'M']]   \n",
       "8806                  [['confident', 'M']]   \n",
       "...                                    ...   \n",
       "20279                  [['challeng', 'M']]   \n",
       "17756                  [['challeng', 'M']]   \n",
       "24269    [['makes decisions easily', 'F']]   \n",
       "11648    [['makes decisions easily', 'F']]   \n",
       "12369    [['makes decisions easily', 'F']]   \n",
       "\n",
       "                                                sentence  \\\n",
       "7574           Maintain strict consumer confidentiality.   \n",
       "21408  You will have your own list of clients to look...   \n",
       "8928   You will be the first person new customers spe...   \n",
       "8820   They will be confident at leading groups of de...   \n",
       "8806       Consultative and confident approach to calls.   \n",
       "...                                                  ...   \n",
       "20279  To be successful in this role you will need to...   \n",
       "17756  But if you want a role that is fascinating and...   \n",
       "24269  She is looking forward to hiring someone who i...   \n",
       "11648  She is looking forward to hiring someone who i...   \n",
       "12369  With a history of ‘firsts’, there has been a q...   \n",
       "\n",
       "                             word_in_Sentence             sort  \n",
       "7574               [['confidentiality', 'M']]  confidentiality  \n",
       "21408                    [['confident', 'M']]        confident  \n",
       "8928                     [['confident', 'M']]        confident  \n",
       "8820   [['confident', 'M'], ['leading', 'M']]        confident  \n",
       "8806                     [['confident', 'M']]        confident  \n",
       "...                                       ...              ...  \n",
       "20279                  [['challenging', 'M']]      challenging  \n",
       "17756                  [['challenging', 'M']]      challenging  \n",
       "24269                        [['quiet', 'F']]            quiet  \n",
       "11648                        [['quiet', 'F']]            quiet  \n",
       "12369                        [['quiet', 'F']]            quiet  \n",
       "\n",
       "[244 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('df1.csv', index=False)\n",
    "df2.to_csv('df2.csv', index=False)\n",
    "df3.to_csv('df3.csv', index=False)\n",
    "df4.to_csv('df4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.read_csv('male_female_last_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_biased_term(list_of_terms):\n",
    "    list_of_terms = list_of_terms.replace('[', '')\n",
    "    list_of_terms = list_of_terms.replace(']', '')\n",
    "    list_of_terms = list_of_terms.replace('\\'', '')\n",
    "    return list_of_terms.split(',')[0]\n",
    "df_new['sort'] = df_new.word_in_Sentence.map(lambda x: return_biased_term(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.sort_values(by=['sort'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO at least 4 at most 10 for each word, then divide into 4\n",
    "to_save = pd.DataFrame(columns=df_new.columns)\n",
    "for word in list(set(df_new.sort.values)):\n",
    "    temp = df_new.loc[df_new.sort == word]\n",
    "    temp = temp.head(5)\n",
    "    if len(temp) > 4:\n",
    "        frames = [to_save, temp]\n",
    "        to_save = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_save = to_save.drop(['sort', 'biased_term'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1, df2, df3, df4 = to_save.iloc[:245], to_save.iloc[245:245+245], to_save.iloc[245+245:245+245+245], to_save.iloc[245+245+245:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('df1_new.csv', index=False)\n",
    "df2.to_csv('df2_new.csv', index=False)\n",
    "df3.to_csv('df3_new.csv', index=False)\n",
    "df4.to_csv('df4_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>word_in_Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>Provide on-going reporting of instrument and a...</td>\n",
       "      <td>[['analyzer', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>Arrange for contract services support for the ...</td>\n",
       "      <td>[['analyzer', 'M'], ['support', 'F']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>Communicate employee concerns relating to inst...</td>\n",
       "      <td>[['analyzer', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>Perform formal and informal audits of the inst...</td>\n",
       "      <td>[['analyzer', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Develop, update, and track action plans pertai...</td>\n",
       "      <td>[['analyzer', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10201</th>\n",
       "      <td>Maintain confidentiality of all interactions.</td>\n",
       "      <td>[['confidentiality', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15886</th>\n",
       "      <td>Ensuring patient confidentiality.</td>\n",
       "      <td>[['confidentiality', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5312</th>\n",
       "      <td>To adhere to company policy and procedures in ...</td>\n",
       "      <td>[['confidentiality', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Maintain confidentiality of all interactions.</td>\n",
       "      <td>[['confidentiality', 'M']]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7574</th>\n",
       "      <td>Maintain strict consumer confidentiality.</td>\n",
       "      <td>[['confidentiality', 'M']]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "1003   Provide on-going reporting of instrument and a...   \n",
       "1004   Arrange for contract services support for the ...   \n",
       "1005   Communicate employee concerns relating to inst...   \n",
       "1006   Perform formal and informal audits of the inst...   \n",
       "1002   Develop, update, and track action plans pertai...   \n",
       "...                                                  ...   \n",
       "10201      Maintain confidentiality of all interactions.   \n",
       "15886                  Ensuring patient confidentiality.   \n",
       "5312   To adhere to company policy and procedures in ...   \n",
       "5996       Maintain confidentiality of all interactions.   \n",
       "7574           Maintain strict consumer confidentiality.   \n",
       "\n",
       "                            word_in_Sentence  \n",
       "1003                     [['analyzer', 'M']]  \n",
       "1004   [['analyzer', 'M'], ['support', 'F']]  \n",
       "1005                     [['analyzer', 'M']]  \n",
       "1006                     [['analyzer', 'M']]  \n",
       "1002                     [['analyzer', 'M']]  \n",
       "...                                      ...  \n",
       "10201             [['confidentiality', 'M']]  \n",
       "15886             [['confidentiality', 'M']]  \n",
       "5312              [['confidentiality', 'M']]  \n",
       "5996              [['confidentiality', 'M']]  \n",
       "7574              [['confidentiality', 'M']]  \n",
       "\n",
       "[245 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('annotated2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"annotated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I'm in the responsibilities:the.\"\n",
    "translator = str.maketrans(' ', ' ', string.punctuation)\n",
    "text = text.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Im in the responsibilitiesthe'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = \"I'm in the responsibilities:the.\"\n",
    "clean = re.sub(r\"[,.;@#?!&$]+\\ *\", \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm in the responsibilities:the \""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I m in the responsibilities:the.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.replace(':', ' ')\n",
    "text.replace('\\'', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['activ',\n",
       " 'adventur',\n",
       " 'aggress',\n",
       " 'ambitio',\n",
       " 'anali',\n",
       " 'assert',\n",
       " 'athlet',\n",
       " 'autonom',\n",
       " 'boast',\n",
       " 'challeng',\n",
       " 'compet',\n",
       " 'confid',\n",
       " 'courag',\n",
       " 'decid',\n",
       " 'decis',\n",
       " 'decis',\n",
       " 'determin',\n",
       " 'domin',\n",
       " 'domina',\n",
       " 'forc',\n",
       " 'greedi',\n",
       " 'headstrong',\n",
       " 'hierarch',\n",
       " 'hostil',\n",
       " 'implus',\n",
       " 'independen',\n",
       " 'individu',\n",
       " 'intellect',\n",
       " 'lead',\n",
       " 'logic',\n",
       " 'masculin',\n",
       " 'object',\n",
       " 'opinion',\n",
       " 'outspoken',\n",
       " 'persist',\n",
       " 'principl',\n",
       " 'reckless',\n",
       " 'stubborn',\n",
       " 'superior',\n",
       " 'self-confiden',\n",
       " 'self-sufficien',\n",
       " 'self-relian',\n",
       " 'manmad',\n",
       " 'chairman',\n",
       " 'son',\n",
       " 'fireman',\n",
       " 'freshman',\n",
       " 'man',\n",
       " 'mankind',\n",
       " 'manpow',\n",
       " 'boyfriend',\n",
       " 'husband',\n",
       " 'policeman',\n",
       " 'walter',\n",
       " 'brother',\n",
       " 'spokesman',\n",
       " 'upperclassman',\n",
       " 'he',\n",
       " 'him',\n",
       " 'hi',\n",
       " 'himself',\n",
       " 'gentleman',\n",
       " 'alumnu',\n",
       " 'alumni',\n",
       " 'man up',\n",
       " 'mr.',\n",
       " 'man-mad',\n",
       " 'the common man',\n",
       " 'mailman',\n",
       " 'steward',\n",
       " 'actor',\n",
       " 'congressman']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "male_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Food52,',\n",
       " 'a',\n",
       " 'fast-growing,',\n",
       " 'James',\n",
       " 'Beard',\n",
       " 'Award-winning',\n",
       " 'online',\n",
       " 'food',\n",
       " 'community',\n",
       " 'and',\n",
       " 'crowd-sourced',\n",
       " 'and',\n",
       " 'curated',\n",
       " 'recipe',\n",
       " 'hub,',\n",
       " 'is',\n",
       " 'currently',\n",
       " 'interviewing',\n",
       " 'full-',\n",
       " 'and',\n",
       " 'part-time',\n",
       " 'unpaid',\n",
       " 'interns',\n",
       " 'to',\n",
       " 'work',\n",
       " 'in',\n",
       " 'a',\n",
       " 'small',\n",
       " 'team',\n",
       " 'of',\n",
       " 'editors,',\n",
       " 'executives,',\n",
       " 'and',\n",
       " 'developers',\n",
       " 'in',\n",
       " 'its',\n",
       " 'New',\n",
       " 'York',\n",
       " 'City',\n",
       " 'headquarters.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.values[0][2].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "he = 0\n",
    "she = 0\n",
    "neutral = 0\n",
    "data_to_label = []\n",
    "\n",
    "for x in df_new['sentence']:\n",
    "    temp = x.lower().split()\n",
    "    male = False\n",
    "    female = False\n",
    "    for y in temp:\n",
    "        if \"he\" == y:\n",
    "            male = True\n",
    "    for z in temp:\n",
    "        if \"she\" == z:\n",
    "            female = True\n",
    "    if male and female:\n",
    "        neutral +=1\n",
    "        data_to_label.append([x, 'neutral'])\n",
    "    elif male:\n",
    "        data_to_label.append([x, 'generic_he'])\n",
    "        he +=1\n",
    "    elif female:\n",
    "        data_to_label.append([x, 'generic_she'])\n",
    "        she +=1\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_generic_she_generic_he = pd.DataFrame(data_to_label)\n",
    "df_generic_she_generic_he.columns = ['sentence', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df_generic_she_generic_he.drop_duplicates()\n",
    "len(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
