{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interprete the Model with Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from eli5.lime import TextExplainer\n",
    "from eli5.lime.samplers import MaskingTextSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from IPython.display import display\n",
    "from torch import cuda\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train = pd.read_csv('../../Dataset/train.csv')\n",
    "train_sentences = train['sentence'].to_list()\n",
    "train_labels = train['word_labels'].to_list()\n",
    "test = pd.read_csv('../../Dataset/test.csv')\n",
    "test_sentences = test['sentence'].to_list()\n",
    "test_labels = test['word_labels'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "MAX_LEN = 128\n",
    "MAX_GRAD_NORM = 10\n",
    "\n",
    "temp_labels = ['Generic She', 'Behavioural Stereotypes', 'O', 'Generic He', 'i-Behavioural Stereotypes', 'i-Stereotyping Bias', 'Societal Stereotypes', 'i-Societal Stereotypes', 'Explicit Marking of Sex'] #set of labels in dataset\n",
    "label2id = {k: v for v, k in enumerate(temp_labels)}\n",
    "id2label = {v: k for v, k in enumerate(temp_labels)}\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# download model from google drive https://drive.google.com/drive/u/0/folders/1XhdQ1rH-p1CGNWDvKcsELc5tEhNQtYtB\n",
    "model = BertForTokenClassification.from_pretrained('./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERExplainerGenerator:\n",
    "    def __init__(self, model, tokenizer, device):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "    \n",
    "    def get_predict_function(self, word_idx):\n",
    "        def predict_func(texts):\n",
    "            probs = np.zeros(shape=(len(texts), len(temp_labels)))\n",
    "            for idx, text in tqdm(enumerate(texts)):\n",
    "                inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "                ids = inputs[\"input_ids\"].to(device)\n",
    "                mask = inputs[\"attention_mask\"].to(device)\n",
    "                outputs = self.model(ids, mask)\n",
    "                logits = outputs[0]\n",
    "\n",
    "                m = torch.nn.Softmax(dim=1)\n",
    "                probabilities = m(logits[0])\n",
    "                probabilities = probabilities.detach().numpy()\n",
    "                probabilities = np.around(probabilities, decimals=2)\n",
    "                tmp = probabilities.sum(axis=1).astype(float)[:, np.newaxis]\n",
    "                probabilities = probabilities / tmp\n",
    "                probabilities = np.around(probabilities, decimals=2)\n",
    "                probabilities = probabilities.tolist()\n",
    "\n",
    "                tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n",
    "                probabilities = [prob for prob, token in zip(probabilities, tokens) if not (token.startswith(\" ##\") or token in ['[CLS]', '[SEP]', '[PAD]'])]\n",
    "\n",
    "                probs[idx] = np.array(probabilities[word_idx])\n",
    "            return probs\n",
    "            \n",
    "        return predict_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_generator = NERExplainerGenerator(model=model, tokenizer=tokenizer, device=device)\n",
    "\n",
    "sampler = MaskingTextSampler(\n",
    "    replacement=\"fm\",\n",
    "    max_replace=0.7,\n",
    "    token_pattern=None,\n",
    "    bow=False\n",
    ")\n",
    "\n",
    "explainer = TextExplainer(\n",
    "    sampler=sampler,\n",
    "    position_dependent=True,\n",
    "    random_state=42,\n",
    "    n_samples=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick randomly n sentences for each bias class\n",
    "generic_she_df = train.loc[train['word_labels'].str.contains(\"Generic She\", case=False)].sample(n=5)\n",
    "generic_he_df = train.loc[train['word_labels'].str.contains(\"Generic He\", case=False)].sample(n=5)\n",
    "bs_df = train.loc[train['word_labels'].str.contains(\"Behavioural Stereotypes\", case=False)].sample(n=5)\n",
    "ss_df = train.loc[train['word_labels'].str.contains(\"Societal Stereotypes\", case=False)].sample(n=5)\n",
    "ems_df = train.loc[train['word_labels'].str.contains(\"Explicit Marking of Sex\", case=False)].sample(n=5)\n",
    "\n",
    "# concat dataframes\n",
    "sample_df = pd.concat([ems_df], ignore_index=False)\n",
    "print(len(sample_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to find word of interest\n",
    "def find_word_idx(label):\n",
    "    label_list = label.split(',')\n",
    "    word_idx = [idx for idx, label in enumerate(label_list) if not label == 'O']\n",
    "    return word_idx[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in sample_df.iterrows():\n",
    "    try:\n",
    "        sentence = train_sentences[index]\n",
    "        words = sentence.split()\n",
    "        label = train_labels[index]\n",
    "\n",
    "        word_idx = find_word_idx(label)\n",
    "        predict_func = explainer_generator.get_predict_function(word_idx=word_idx)\n",
    "        explainer.fit(sentence, predict_func)\n",
    "\n",
    "        print('lime interpretation of the sentence: ')\n",
    "        print(sentence)\n",
    "        print('with label: ')\n",
    "        print(label)\n",
    "        print(f'for the word {words[word_idx]}')\n",
    "\n",
    "        display(explainer.show_prediction(target_names=temp_labels))\n",
    "        display(explainer.show_weights(target_names=temp_labels))\n",
    "        print(\"prediction of lime model\")\n",
    "        print(explainer.y_proba_)\n",
    "    except:\n",
    "        print(\"Probability problem\")\n",
    "        print(sentence)\n",
    "        print(label)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d74c30388a43eb0b48b7085e6e93303a40808c3042a376b584e90cd5a9f7268"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('MRP2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
